{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-06T16:38:30.978682Z","iopub.execute_input":"2021-09-06T16:38:30.979087Z","iopub.status.idle":"2021-09-06T16:38:30.987959Z","shell.execute_reply.started":"2021-09-06T16:38:30.979054Z","shell.execute_reply":"2021-09-06T16:38:30.986866Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/tabular-playground-series-sep-2021/train.csv\n/kaggle/input/tabular-playground-series-sep-2021/test.csv\n/kaggle/input/tabular-playground-series-sep-2021/sample_solution.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Table of content\n- A. Prepare data with Null values for the example\n- B. Methods to handle the missing values\n    - 1. Drop the data\n    - 2. Fill the places with any of 5 Ms (Mean/Median/Mode/Max/Min)\n    - 3. Fill the place with some constant value\n    - 4. Predict the missing values\n    - 5. Use models which support missing values","metadata":{}},{"cell_type":"markdown","source":"# A. Prepare data with Null values for the example\n","metadata":{}},{"cell_type":"code","source":"data_ = pd.read_csv(\"../input/tabular-playground-series-sep-2021/train.csv\",index_col = 0)","metadata":{"execution":{"iopub.status.busy":"2021-09-06T18:11:10.582024Z","iopub.execute_input":"2021-09-06T18:11:10.582481Z","iopub.status.idle":"2021-09-06T18:11:34.289044Z","shell.execute_reply.started":"2021-09-06T18:11:10.582440Z","shell.execute_reply":"2021-09-06T18:11:34.287907Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"# keeping just 50 rows for my example.\ndef create_data():\n    data = data_.iloc[0:50,30:50]\n    return data\ndata = create_data()\nprint(\"Shape of the data------>{}\".format(data.shape))\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T18:11:37.365549Z","iopub.execute_input":"2021-09-06T18:11:37.366235Z","iopub.status.idle":"2021-09-06T18:11:37.411158Z","shell.execute_reply.started":"2021-09-06T18:11:37.366177Z","shell.execute_reply":"2021-09-06T18:11:37.409672Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Shape of the data------>(50, 20)\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"        f31       f32       f33       f34           f35       f36      f37  \\\nid                                                                           \n0   0.75050   18509.0  146820.0 -0.000276  1.090600e+16  1705.400   414.29   \n1   1.50330  238000.0   21440.0 -0.001344  3.079400e+16   229.100   844.82   \n2   1.13180   27940.0  862460.0 -0.002207  5.849100e+13  -897.840      NaN   \n3   0.98941  301200.0       NaN -0.000007 -9.299200e+13   -10.818  1020.30   \n4   0.97413  142620.0  231350.0  0.001257  1.012500e+16    51.508   293.76   \n\n       f38     f39       f40      f41       f42      f43      f44       f45  \\\nid                                                                            \n0   3.5392  1888.0  0.968930  18.3880 -0.001583   7.7059   5.9325  0.025693   \n1   1.4680  4726.5  0.915380  -1.5321  0.982600   7.1112   2.0797  0.042321   \n2   1.3561  3063.4  0.086232  16.1060  0.001481  11.4760   5.3430  0.012162   \n3   2.9553  3342.5 -0.000372  17.0110  0.095268   5.7448  15.8830  0.037934   \n4   1.3351  3042.1  0.006791  94.8890  0.917090   8.7369      NaN  0.020281   \n\n       f46      f47      f48       f49       f50  \nid                                                \n0   4.5604  0.61122  10.7950  0.341930  0.235010  \n1   4.2523  0.41871   5.4499  0.012737  0.386470  \n2   4.1018 -0.88270   8.1228 -0.676690  0.337700  \n3   4.4860 -0.88909   8.4384 -1.189800  0.001391  \n4   3.9115  0.65634   6.1410 -1.089600  0.247940  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f31</th>\n      <th>f32</th>\n      <th>f33</th>\n      <th>f34</th>\n      <th>f35</th>\n      <th>f36</th>\n      <th>f37</th>\n      <th>f38</th>\n      <th>f39</th>\n      <th>f40</th>\n      <th>f41</th>\n      <th>f42</th>\n      <th>f43</th>\n      <th>f44</th>\n      <th>f45</th>\n      <th>f46</th>\n      <th>f47</th>\n      <th>f48</th>\n      <th>f49</th>\n      <th>f50</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.75050</td>\n      <td>18509.0</td>\n      <td>146820.0</td>\n      <td>-0.000276</td>\n      <td>1.090600e+16</td>\n      <td>1705.400</td>\n      <td>414.29</td>\n      <td>3.5392</td>\n      <td>1888.0</td>\n      <td>0.968930</td>\n      <td>18.3880</td>\n      <td>-0.001583</td>\n      <td>7.7059</td>\n      <td>5.9325</td>\n      <td>0.025693</td>\n      <td>4.5604</td>\n      <td>0.61122</td>\n      <td>10.7950</td>\n      <td>0.341930</td>\n      <td>0.235010</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.50330</td>\n      <td>238000.0</td>\n      <td>21440.0</td>\n      <td>-0.001344</td>\n      <td>3.079400e+16</td>\n      <td>229.100</td>\n      <td>844.82</td>\n      <td>1.4680</td>\n      <td>4726.5</td>\n      <td>0.915380</td>\n      <td>-1.5321</td>\n      <td>0.982600</td>\n      <td>7.1112</td>\n      <td>2.0797</td>\n      <td>0.042321</td>\n      <td>4.2523</td>\n      <td>0.41871</td>\n      <td>5.4499</td>\n      <td>0.012737</td>\n      <td>0.386470</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.13180</td>\n      <td>27940.0</td>\n      <td>862460.0</td>\n      <td>-0.002207</td>\n      <td>5.849100e+13</td>\n      <td>-897.840</td>\n      <td>NaN</td>\n      <td>1.3561</td>\n      <td>3063.4</td>\n      <td>0.086232</td>\n      <td>16.1060</td>\n      <td>0.001481</td>\n      <td>11.4760</td>\n      <td>5.3430</td>\n      <td>0.012162</td>\n      <td>4.1018</td>\n      <td>-0.88270</td>\n      <td>8.1228</td>\n      <td>-0.676690</td>\n      <td>0.337700</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.98941</td>\n      <td>301200.0</td>\n      <td>NaN</td>\n      <td>-0.000007</td>\n      <td>-9.299200e+13</td>\n      <td>-10.818</td>\n      <td>1020.30</td>\n      <td>2.9553</td>\n      <td>3342.5</td>\n      <td>-0.000372</td>\n      <td>17.0110</td>\n      <td>0.095268</td>\n      <td>5.7448</td>\n      <td>15.8830</td>\n      <td>0.037934</td>\n      <td>4.4860</td>\n      <td>-0.88909</td>\n      <td>8.4384</td>\n      <td>-1.189800</td>\n      <td>0.001391</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.97413</td>\n      <td>142620.0</td>\n      <td>231350.0</td>\n      <td>0.001257</td>\n      <td>1.012500e+16</td>\n      <td>51.508</td>\n      <td>293.76</td>\n      <td>1.3351</td>\n      <td>3042.1</td>\n      <td>0.006791</td>\n      <td>94.8890</td>\n      <td>0.917090</td>\n      <td>8.7369</td>\n      <td>NaN</td>\n      <td>0.020281</td>\n      <td>3.9115</td>\n      <td>0.65634</td>\n      <td>6.1410</td>\n      <td>-1.089600</td>\n      <td>0.247940</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# find the missing values.\nfeatures = data.columns.tolist()[0:-1]\n\n\n#find the missing values w.r.t. column\ncolum_missing = data.isnull().sum()\n# find the missing values w.r.t. row(number of missing values in the particular row)\nrow_missing = data[features].isnull().sum(axis=1)\n\n# add the missing values to row to the dataframe as a new value\ndata['no_of_missing_data'] = row_missing","metadata":{"execution":{"iopub.status.busy":"2021-09-06T17:45:06.739464Z","iopub.execute_input":"2021-09-06T17:45:06.739888Z","iopub.status.idle":"2021-09-06T17:45:06.748161Z","shell.execute_reply.started":"2021-09-06T17:45:06.739853Z","shell.execute_reply":"2021-09-06T17:45:06.747362Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"colum_missing","metadata":{"execution":{"iopub.status.busy":"2021-09-06T17:45:07.149444Z","iopub.execute_input":"2021-09-06T17:45:07.149978Z","iopub.status.idle":"2021-09-06T17:45:07.157232Z","shell.execute_reply.started":"2021-09-06T17:45:07.149946Z","shell.execute_reply":"2021-09-06T17:45:07.156185Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"f31    0\nf32    1\nf33    2\nf34    1\nf35    1\nf36    2\nf37    3\nf38    0\nf39    0\nf40    0\nf41    1\nf42    1\nf43    1\nf44    2\nf45    2\nf46    0\nf47    0\nf48    1\nf49    0\nf50    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"print(f\"Total number of missing values in training dataset---->{data.shape[0]}\")\n\n# compare this to the whole data\nno_of_missing_rows = (data['no_of_missing_data'] != 0).sum()\nprint(\"\\n{0:{fill}{align}80}\\n\".format(\" Data Summary \" , fill = \"=\", align = \"^\"))\nprint(f\"Total rows -----------------------> {data.shape[0]}\\nNumber of rows has missing data---> {no_of_missing_rows}\\n{'-'*50}\\nNumber of rows has full data--------> {data.shape[0] - no_of_missing_rows}\")\n","metadata":{"execution":{"iopub.status.busy":"2021-09-06T17:45:09.435512Z","iopub.execute_input":"2021-09-06T17:45:09.435897Z","iopub.status.idle":"2021-09-06T17:45:09.443715Z","shell.execute_reply.started":"2021-09-06T17:45:09.435866Z","shell.execute_reply":"2021-09-06T17:45:09.442491Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Total number of missing values in training dataset---->50\n\n================================= Data Summary =================================\n\nTotal rows -----------------------> 50\nNumber of rows has missing data---> 17\n--------------------------------------------------\nNumber of rows has full data--------> 33\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# B. Methods to handle the missing values\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Drop the data","metadata":{}},{"cell_type":"markdown","source":"In this method, we simply delete the rows or features/columns which has the Null value. We will delete a row if there are more missing values (say 70-75%) same goes for the columns. This is only preferred to use when we have enough samples in the dataset.  We can delete a feature/column when it has less feature importance over prediction. One has to make sure there is no add of bias, after we have removed the data.\n\nBuild-in functions:\n- dropna() --> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html\n\nPros: \n1. Removing this unwanted data sometimes make our model more accurate.\n2. Deleting a column with less importance is better, since there is no use of keeping this with full of null values and no use of speding time handling this.\n\nCons:\n1. Loss of information.\n2. Redure prediction accuracy --> when we have a big number of missing values.","metadata":{}},{"cell_type":"code","source":"# Example.\nrow_drop = create_data()\n# Drop the rows with null value\nrow_drop.dropna( how = 'any' , inplace = True) # we can change how to any/all . if 'all' the row will be deleted when it has all values as null values.\nrow_drop.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T17:51:22.978663Z","iopub.execute_input":"2021-09-06T17:51:22.979062Z","iopub.status.idle":"2021-09-06T17:51:22.991665Z","shell.execute_reply.started":"2021-09-06T17:51:22.979030Z","shell.execute_reply":"2021-09-06T17:51:22.990513Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"f31    0\nf32    0\nf33    0\nf34    0\nf35    0\nf36    0\nf37    0\nf38    0\nf39    0\nf40    0\nf41    0\nf42    0\nf43    0\nf44    0\nf45    0\nf46    0\nf47    0\nf48    0\nf49    0\nf50    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Drop the column --> here the f37  has '3' values. we can delete if we want to..\ndata_ = create_data()\ndata_ = data_.drop('f37', axis = 1)\ndata_.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-06T17:51:26.357605Z","iopub.execute_input":"2021-09-06T17:51:26.358001Z","iopub.status.idle":"2021-09-06T17:51:26.395881Z","shell.execute_reply.started":"2021-09-06T17:51:26.357970Z","shell.execute_reply":"2021-09-06T17:51:26.394779Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"        f31       f32       f33       f34           f35       f36     f38  \\\nid                                                                          \n0   0.75050   18509.0  146820.0 -0.000276  1.090600e+16  1705.400  3.5392   \n1   1.50330  238000.0   21440.0 -0.001344  3.079400e+16   229.100  1.4680   \n2   1.13180   27940.0  862460.0 -0.002207  5.849100e+13  -897.840  1.3561   \n3   0.98941  301200.0       NaN -0.000007 -9.299200e+13   -10.818  2.9553   \n4   0.97413  142620.0  231350.0  0.001257  1.012500e+16    51.508  1.3351   \n\n       f39       f40      f41       f42      f43      f44       f45     f46  \\\nid                                                                            \n0   1888.0  0.968930  18.3880 -0.001583   7.7059   5.9325  0.025693  4.5604   \n1   4726.5  0.915380  -1.5321  0.982600   7.1112   2.0797  0.042321  4.2523   \n2   3063.4  0.086232  16.1060  0.001481  11.4760   5.3430  0.012162  4.1018   \n3   3342.5 -0.000372  17.0110  0.095268   5.7448  15.8830  0.037934  4.4860   \n4   3042.1  0.006791  94.8890  0.917090   8.7369      NaN  0.020281  3.9115   \n\n        f47      f48       f49       f50  \nid                                        \n0   0.61122  10.7950  0.341930  0.235010  \n1   0.41871   5.4499  0.012737  0.386470  \n2  -0.88270   8.1228 -0.676690  0.337700  \n3  -0.88909   8.4384 -1.189800  0.001391  \n4   0.65634   6.1410 -1.089600  0.247940  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>f31</th>\n      <th>f32</th>\n      <th>f33</th>\n      <th>f34</th>\n      <th>f35</th>\n      <th>f36</th>\n      <th>f38</th>\n      <th>f39</th>\n      <th>f40</th>\n      <th>f41</th>\n      <th>f42</th>\n      <th>f43</th>\n      <th>f44</th>\n      <th>f45</th>\n      <th>f46</th>\n      <th>f47</th>\n      <th>f48</th>\n      <th>f49</th>\n      <th>f50</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.75050</td>\n      <td>18509.0</td>\n      <td>146820.0</td>\n      <td>-0.000276</td>\n      <td>1.090600e+16</td>\n      <td>1705.400</td>\n      <td>3.5392</td>\n      <td>1888.0</td>\n      <td>0.968930</td>\n      <td>18.3880</td>\n      <td>-0.001583</td>\n      <td>7.7059</td>\n      <td>5.9325</td>\n      <td>0.025693</td>\n      <td>4.5604</td>\n      <td>0.61122</td>\n      <td>10.7950</td>\n      <td>0.341930</td>\n      <td>0.235010</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.50330</td>\n      <td>238000.0</td>\n      <td>21440.0</td>\n      <td>-0.001344</td>\n      <td>3.079400e+16</td>\n      <td>229.100</td>\n      <td>1.4680</td>\n      <td>4726.5</td>\n      <td>0.915380</td>\n      <td>-1.5321</td>\n      <td>0.982600</td>\n      <td>7.1112</td>\n      <td>2.0797</td>\n      <td>0.042321</td>\n      <td>4.2523</td>\n      <td>0.41871</td>\n      <td>5.4499</td>\n      <td>0.012737</td>\n      <td>0.386470</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.13180</td>\n      <td>27940.0</td>\n      <td>862460.0</td>\n      <td>-0.002207</td>\n      <td>5.849100e+13</td>\n      <td>-897.840</td>\n      <td>1.3561</td>\n      <td>3063.4</td>\n      <td>0.086232</td>\n      <td>16.1060</td>\n      <td>0.001481</td>\n      <td>11.4760</td>\n      <td>5.3430</td>\n      <td>0.012162</td>\n      <td>4.1018</td>\n      <td>-0.88270</td>\n      <td>8.1228</td>\n      <td>-0.676690</td>\n      <td>0.337700</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.98941</td>\n      <td>301200.0</td>\n      <td>NaN</td>\n      <td>-0.000007</td>\n      <td>-9.299200e+13</td>\n      <td>-10.818</td>\n      <td>2.9553</td>\n      <td>3342.5</td>\n      <td>-0.000372</td>\n      <td>17.0110</td>\n      <td>0.095268</td>\n      <td>5.7448</td>\n      <td>15.8830</td>\n      <td>0.037934</td>\n      <td>4.4860</td>\n      <td>-0.88909</td>\n      <td>8.4384</td>\n      <td>-1.189800</td>\n      <td>0.001391</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.97413</td>\n      <td>142620.0</td>\n      <td>231350.0</td>\n      <td>0.001257</td>\n      <td>1.012500e+16</td>\n      <td>51.508</td>\n      <td>1.3351</td>\n      <td>3042.1</td>\n      <td>0.006791</td>\n      <td>94.8890</td>\n      <td>0.917090</td>\n      <td>8.7369</td>\n      <td>NaN</td>\n      <td>0.020281</td>\n      <td>3.9115</td>\n      <td>0.65634</td>\n      <td>6.1410</td>\n      <td>-1.089600</td>\n      <td>0.247940</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 2. Fill the places with any of 5 Ms (Mean/Median/Mode/Max/Min)","metadata":{}},{"cell_type":"markdown","source":"In this method, we can replace the null value with some approximations (Average(mean), Median, Mode, Min, and Max). This method can be used with the numerical columns. Even this is an approximate calculation for the null value, It is better than deleting the rows and columns. The Mean, Median, Mode are a statistical approach to handling the missing values. \n\nBuild-in functions:\n- fillna() --> https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html ( with different methods)\n- SimpleImputer--> https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n\nPros:\n1. There is no loss of information.\n2. Better approach with small dataset.\n\nCons:\n1. Imputing the approximations add variance and bias.","metadata":{}},{"cell_type":"markdown","source":"### Example with SimpleImputer()\nChnage the strategy to ----> mean / median / most_frequent(mode)","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n\ndata_before = data.copy()\n#print(data_before.isnull().sum())\ndata_after = pd.DataFrame(imputer.fit_transform(data_before))\n#print(data_after.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-09-06T18:12:55.430574Z","iopub.execute_input":"2021-09-06T18:12:55.431271Z","iopub.status.idle":"2021-09-06T18:12:55.442730Z","shell.execute_reply.started":"2021-09-06T18:12:55.431217Z","shell.execute_reply":"2021-09-06T18:12:55.441878Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# Example to replace with max in that column.\ndata_max = data.copy()\nfor f in data.columns.tolist():\n    ","metadata":{},"execution_count":null,"outputs":[]}]}